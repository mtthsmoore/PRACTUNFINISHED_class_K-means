{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings;\n",
    "warnings.filterwarnings('ignore');\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VO24y4Jju21u"
   },
   "source": [
    "# Splice site prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhcU9Uucu21v"
   },
   "source": [
    "Gene splicing is a post-transcriptional modification in which a single gene can code for multiple proteins. Gene Splicing is done in eukaryotes, prior to mRNA translation, by the differential inclusion or exclusion of regions of pre-mRNA. Gene splicing is an important source of protein diversity.\n",
    "\n",
    "The vast majority of splice sites are characterized by the presence of specific dimers on the intronic side of the splice site: \"GT\" for donor and \"AG\" for acceptor sites. In this project you will fit a classification model for acceptor splice site prediction in DNA sequences.\n",
    "\n",
    "This model will consider each AG in the DNA as a candidate acceptor site, extract a local context surrounding the candidate acceptor site, represent the candidate site as a feature vector and the predict the class ('acceptor site' or 'not acceptor site') by applying the model in the constructed feature vector.\n",
    "\n",
    "This what the training data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrdBiQtAu21v"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_data/master/practicum/Classification/acceptor_sites_dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "_lJt4Vopu212",
    "outputId": "5be0c1b0-96cc-485c-b776-f05b91617bfb"
   },
   "outputs": [],
   "source": [
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rXgIExxtu216"
   },
   "source": [
    "There are just two columns. \n",
    "\n",
    "The column \"sequence\" contains the local context DNA sequence. We can see that nucleotide positions 11 and 12 in the sequence are always \"A\" and \"G\". These are the candidate acceptor sites with a local context that consists of 10 nucleotides upstream en 10 nucleotides downstream the AG. \n",
    "\n",
    "The column \"label\" contains the class of the candidate acceptor site: 1 for \"acceptor site\" and -1 for \"not acceptor site\". \n",
    "\n",
    "*How many sequences does the dataset contain for each class?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "PYhNkKz3u217",
    "outputId": "22209f38-cbcb-47f7-df40-7b83cffc09c5"
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "\n",
    "###End code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_data/master/practicum/Classification/acceptor_sites_dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute features from the `column` we first concatenate the trainging and testing data into one DataFrame. In this manner the training and testing data are processed in exactly the same way. We can later reconstruct the training and testing DataFrames.\n",
    "\n",
    "*Use the Pandas function `concat()` to concatenate the training and testing data into a DataFrame called `data`. The training dat should be the first rows, with the testing data beneath those rows:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start code here\n",
    "data = \n",
    "###End code here\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pop the `label` column from the `data` DataFrame and assigned it to variable `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start code here\n",
    "y = \n",
    "###End code here\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teweqTUhu21_"
   },
   "source": [
    "We need to represent the local context DNA sequence as a feature vector suitable for model fitting. This process is known as **feature engineering**. \n",
    "\n",
    "The \"AG\" dinucleotide in the middle of each local context sequence is the same for both classes, i.e. it does not provide any discriminative information. So, there is not rational behind computing features from this part of the local context sequence.\n",
    "\n",
    "*Use the Pandas DataFrame `.apply()` method to remove the middle \"AG\" dinucleotides in the DNA sequences (don't create a new column):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())\n",
    "\n",
    "###Start code here\n",
    "data[\"sequence\"] = \n",
    "###End code here\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZkQumNiu22E"
   },
   "source": [
    "First, we create a feature for each of the nucleotide positions in the local context DNA sequence.\n",
    "\n",
    "The [pandas.Series.str.split](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) function splits a string in a column (pandas.Series) from the beginning, at the specified delimiter string.\n",
    "\n",
    "*Use this function to split the `sequence` column into one column for each nucleotide positon. Put the resulting columns in a DataFrame called `data_features`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start code here\n",
    "data_features = \n",
    "###End code here\n",
    "\n",
    "data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Pandas DataFrame, the `.columns` attirbute contains a list with the column names.\n",
    "\n",
    "*Rename the columns to the relative position of the nucleotide position in the local context (from -10 to 10):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start code here\n",
    "data_features.columns = \n",
    "###End code here\n",
    "\n",
    "data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MJXJBj0u22I"
   },
   "source": [
    "Next we apply `sklearn.preprocessing.LabelEncoder` to repace each nucleotide by a number.\n",
    "\n",
    "*Create a Pandas DataFrame `data_features_int_encoding` by applying the `LabelEncoder` on each feature in `data_features`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "nFRdEtCeu22J",
    "outputId": "aa2c17a9-c4bb-46ab-f781-9b9d276e8e59"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "data_features_int_encoding = pd.DataFrame()\n",
    "for col in data_features.columns:\n",
    "    ###Start code here\n",
    "    data_features_int_encoding[col] = \n",
    "    ###End code here\n",
    "    \n",
    "data_features_int_encoding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we recontruct the training and testing data DataFrames based on the number of datapoints in the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features_int_encoding_train = data_features_int_encoding.iloc[:len(data_train),:]\n",
    "data_features_int_encoding_test = data_features_int_encoding.iloc[len(data_train):,:]\n",
    "\n",
    "y_train = y.iloc[:len(data_train)]\n",
    "y_test = y.iloc[len(data_train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0573K2rRu22W"
   },
   "source": [
    "Now we evaluate the generalization performance of a logisitc regression model with hyperparameters $C=0.1$ on the dataset `data_features_int_encoding` using 10-fold cross-validation. \n",
    "\n",
    "*Apply the `cross_val_score()` function to compute an accuracy score for each fold in the CV:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "jc7J8SrIu22X",
    "outputId": "5d9ba961-b669-4a94-a9d7-5243d57cab27"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "###Start code here\n",
    "model = \n",
    "scores = \n",
    "###Start code here\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z9SWqTScu22u"
   },
   "source": [
    "*Fit a logistic regression model on the train set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "gHuDj5xsu22v",
    "outputId": "d8c46421-8aa9-4abe-9fd3-e1c1c7397ea3"
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "\n",
    "###End code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_gu0seZu221"
   },
   "source": [
    "*Make predictions for the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzX1UJqlu222"
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "predictions = \n",
    "###End code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNIux5gFu227"
   },
   "source": [
    "Scikit-learn offers many metrics to evaluate model predictions. These functions are contained in the `metrics` module of `sklearn`. \n",
    "\n",
    "*Can you find how to compute the accuracy of these predictions (use the `metrics`module)?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "TTFGB05gu228",
    "outputId": "ab15f4d5-af1a-4f1d-c3ba-c377dbf3abf3"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "###Start code here\n",
    "score_acc = \n",
    "###End code here\n",
    "\n",
    "print(score_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPu8YDA2u23D"
   },
   "source": [
    "An accuracy above 90% seems like a good score. But is it? Let's consider a model that predicts class \"-1\" for all test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kV1yMLOu23E"
   },
   "outputs": [],
   "source": [
    "predictions_zero = [-1]*len(data_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efNP_I-Ju23I"
   },
   "source": [
    "*What is the accuracy of these predictions?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "fmdBsSaou23K",
    "outputId": "a4efb18f-1f8a-4cb3-e49b-16ae5938a95a"
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "score_acc = \n",
    "###End code here\n",
    "\n",
    "print(score_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lZ3nJUPu23P"
   },
   "source": [
    "So this should be a good score as well, even though we did not learn anything.\n",
    "\n",
    "For classification tasks where the classes are highly imbalanced, accuracy is not a good metric to evaluate the generalization performance. In fact, if there are 0.1% \"AG\" dinucleotides in a genome that are true acceptor sites then a model that predicts class \"-1\" for each \"AG\" would have an accuracy of 99.9%.\n",
    "\n",
    "We have seen how a ROC curve plots the true positives rate against the false positives rate. Both these metrics focus on the positive class, in our case the true acceptor sites. These metrics are much more suitable to evalute the performance of models on tasks with highly imbalanced classes. To transform a ROC curve into one metric we can use the area under the curve (AUC). \n",
    "\n",
    "*What is the AUC score of the predictions computed by the linear regression model we fitted?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "nTjM_o7Iu23Q",
    "outputId": "f9c9fda5-fa07-4452-cf35-8e36ad114b3e"
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "score_auc = \n",
    "###End code here\n",
    "\n",
    "print(score_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbuR3_0Uu23V"
   },
   "source": [
    "You should see a negative value. \n",
    "\n",
    "To compute the AUC, we need the predictions to be scores (a continuous value) rather than class labels (discrete values).\n",
    "\n",
    "For logistic regression these scores are the class probabilities predicted by the model (a value between 0 and 1). \n",
    "\n",
    "We can obtain these scores with the `predict_proba()` function of the `LogisticRegression` module as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "xMT2X0i7u23W",
    "outputId": "069d78eb-be22-401c-cf3d-c98ad4fc5a6f"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(data_features_int_encoding_test)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecMykZJcu23h"
   },
   "source": [
    "The first and second column contain the predicted probabilities for class '-1' and '1' respectively. To compute the AUC we need to use the positive class probabilities. \n",
    "\n",
    "*What is the AUC now?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "k7Zj60JBu23i",
    "outputId": "d32a2e3d-6baa-43ee-969f-afa70c6f08e1"
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "score_auc = \n",
    "###End code here\n",
    "\n",
    "print(score_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EudhUPu-u23o"
   },
   "source": [
    "Is this good generalization performance?\n",
    "\n",
    "Transforming categorical features into ordered integers is maybe not a good idea as the nucleotides don't have any ordering (the columns are not ordinal features). \n",
    "\n",
    "It is better to transform a categorical feature into one binary feature for each category (known as *one-hot* encoding). \n",
    "\n",
    "*Use the Pandas function `get_dummies()` to compute one-hot encoded features (put them in a DataFrame called `data_features_onehot_encoding`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start code here\n",
    "data_features_onehot_encoding = \n",
    "###End code here\n",
    "\n",
    "data_features_onehot_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfAOG8SBu24E"
   },
   "source": [
    "Evaluate the generalization performance of a logisitc regression model with hyperparameters $C=1$ on the training data in `data_features_onehot_encoding` using 10-fold cross-validation. \n",
    "\n",
    "The `cross_val_score()` has a function parameter called `scoring` that allows you to set different scoring metrics.\n",
    "\n",
    "*Use the `cross_val_score()` function to compute the mean AUC of the CV-scores.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "bq2cZVNSu24F",
    "outputId": "159ebfd3-fb04-40af-a6b2-8137aab19f76"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.1)\n",
    "\n",
    "###Start code here\n",
    "data_features_onehot_encoding_train =\n",
    "data_features_onehot_encoding_test = \n",
    "\n",
    "score_auc = \n",
    "###End code here\n",
    "\n",
    "print(score_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vqh-I3zuu24L"
   },
   "source": [
    "*What is the AUC on `data_test`?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "GeCkxuubu24M",
    "outputId": "502dc7a6-1997-4961-8a70-bc1a02b4b6bd"
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "\n",
    "###Start code here\n",
    "\n",
    "score_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2w-jdU-gu24Q"
   },
   "source": [
    "Is this close to what your CV is telling you?\n",
    "\n",
    "We have used hyperparameter $C=1$ for the logistic regression model. \n",
    "\n",
    "*Is there a better value for this regularization parameter (use `GridSearchCV`)?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "B63LA0zwu24S",
    "outputId": "1e4c5b6c-d833-4c9e-f6bb-2cc1e8c817e9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search_space = [0.001,0.01,0.1,1,10,100]\n",
    "print(params)\n",
    "params = dict(C=search_space)\n",
    "\n",
    "###Start code here\n",
    "\n",
    "###End code here\n",
    "\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SjoFP1_bu24W"
   },
   "source": [
    "*What is the 10-CV AUC performance with this value for $C$?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "hWxVj0hRu24X",
    "outputId": "6330ac78-44b6-43c2-da1f-8798b3b1a1f6"
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "\n",
    "###Start code here\n",
    "\n",
    "score_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ytpwmh2wu24c"
   },
   "source": [
    "*What is the AUC performance on the test set for this value of $C$?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "k5906bHvu24d",
    "outputId": "917b912d-3596-4670-940d-8057286470f2"
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "\n",
    "###End code here\n",
    "\n",
    "score_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "wRe1CLnUu24l"
   },
   "source": [
    "Is this closer to the AUC you computed using 10-CV?\n",
    "\n",
    "In scikit-learn a fitted logistic regression model has the fitted modelparameter values stored in `.coef_[0]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "8f-NBEUt4AjE",
    "outputId": "403323ff-3fba-48c0-b898-ad01850826bc"
   },
   "outputs": [],
   "source": [
    "print(model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdPAICuc4NWT"
   },
   "source": [
    "For logistic regression this is one modelparameter for each feature (plus the interecept, which is not in `.coef_[0]`). \n",
    "\n",
    "Recall that for logistic regression a prediction is made by multiplying each fitted modelparameter with the corresponding feature, summing them and then squeezing this sum between 0 and 1 with the logistic function. \n",
    "\n",
    "Since all features have values 0 or 1, the modelparameter values indicate the contribution (importance) of a feature during prediction.\n",
    "\n",
    "First we put the feature names and modelparameter values in a new DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "1Mnte18-u242",
    "outputId": "74bff443-ad92-46cb-e5a2-cfee028d100f"
   },
   "outputs": [],
   "source": [
    "F_importances = []\n",
    "for feature_name, modelparameter in zip(data_features_onehot_encoding.columns,model.coef_[0]):\n",
    "    F_importances.append([feature_name,modelparameter])\n",
    "F_importances = pd.DataFrame(F_importances,columns=[\"feature_name\",\"importance\"])\n",
    "F_importances.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8SwWB_xQ8w8g"
   },
   "source": [
    "*Use the Seaborn `.barplot()` method to create a plot like this:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0N9sbu79xoi"
   },
   "source": [
    "*Create a plot that looks like this:*\n",
    "\n",
    "![plot](https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_data/master/practicum/Classification/AG_plot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "colab_type": "code",
    "id": "ntsnD5Kwu25B",
    "outputId": "562c9b9d-110f-4923-e0ac-b259a3f7dedc"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def get_nuc(x):\n",
    "    return(x.split(\"_\")[1])\n",
    "\n",
    "def get_position(x):\n",
    "    if x.split(\"_\")[0] == \"A\": return 0\n",
    "    if x.split(\"_\")[0] == \"G\": return 0\n",
    "    return(int(x.split(\"_\")[0]))\n",
    "\n",
    "###Start code here\n",
    "\n",
    "#End code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2.1._Classification_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
