{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "2.1._Classification_solutions.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO24y4Jju21u",
        "colab_type": "text"
      },
      "source": [
        "# Splice site prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhcU9Uucu21v",
        "colab_type": "text"
      },
      "source": [
        "Most eukaryotic genes undergo intron splicing events. These happen at the level of mRNA, after transcription and before translation. Pre-mRNA consists of exons, which are the proteincoding regions, and introns, which are the intervening sections in between. As a base rule, the spliceosome cuts out introns, retaining the consecutive exons to form mature mRNA. This mature mRNA is then translated to protein.\n",
        "\n",
        "In this practical you will build a classification model for gene splice site prediction from DNA sequences. The vast majority of splice sites are characterized by the presence of specific dimers on the intronic side of the splice site: \"GT\" for donor and \"AG\" for acceptor sites. Yet, only about 0.1-1% of all \"GT\" and \"AG\" occurrences in the genome represent true splice sites. \n",
        "\n",
        "We will focus on acceptor site prediction. You are given the following data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrdBiQtAu21v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554/master/practicum/3._Classification/acceptor_sites_dataset_train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lJt4Vopu212",
        "colab_type": "code",
        "outputId": "87820f02-0f0c-45db-a134-1d83a86aa028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>TTTGAATTGTAGGTGTCCTGCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>TATTTTTTAAAGAACTGGAAGA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>TTTCTTTTTCAGATGAAGAATG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>TATTAATTTCAGTTTGGTTGTT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>TAAAAATTTAAGTTCGTCCCGA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                sequence\n",
              "0      1  TTTGAATTGTAGGTGTCCTGCT\n",
              "1      1  TATTTTTTAAAGAACTGGAAGA\n",
              "2      1  TTTCTTTTTCAGATGAAGAATG\n",
              "3      1  TATTAATTTCAGTTTGGTTGTT\n",
              "4      1  TAAAAATTTAAGTTCGTCCCGA"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXgIExxtu216",
        "colab_type": "text"
      },
      "source": [
        "There are only two columns. The column \"sequence\" contains a local DNA context sequence that surrounds a candidate acceptor site (nucleotides at positions 11 and 12 in the sequence are always \"A\" and \"G\" respectively), so these positions are candidate gene acceptor sites. The column \"label\" indicates the class: 1 for \"is acceptor site\" and -1 for \"is not acceptor site\". The goal is to predict the target from the local context sequence of the candidate acceptor site. \n",
        "\n",
        "*How many sequences does the dataset contain for each class?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYhNkKz3u217",
        "colab_type": "code",
        "outputId": "aee9f797-9f3f-4445-81ae-cc03b17d7b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "###Start code here\n",
        "data['label'].value_counts()\n",
        "###End code here"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    1503\n",
              " 1     145\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teweqTUhu21_",
        "colab_type": "text"
      },
      "source": [
        "Next, useful features need to be computed from the DNA sequences, a process known as **feature engineering**. \n",
        "\n",
        "The Pandas `.apply()` method allows us the process the values in a DataFrame column to create a new column. We will apply this function to compute feature vectors from the `sequence` column in the `data` DataFrame.  \n",
        "\n",
        "The \"AG\" in the middle of each context sequence is the same for both classes, i.e. it does not provide any discriminative information. So, We shouldn't compute features from the middle AG dinculeotide in the local context sequence.\n",
        "\n",
        "*Use the Pandas DataFrame `.apply()` method to remove the middle \"AG\" dinucleotides in the DNA sequences (don't create a new column):*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8ThMz7Su22A",
        "colab_type": "code",
        "outputId": "f2d8ab08-3877-477e-e39f-3efc8f2d8bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "print(data.head())\n",
        "\n",
        "###Start code here\n",
        "def remove_AG(x):\n",
        "    return x[0:10]+x[12:22]\n",
        "\n",
        "data[\"sequence\"] = data[\"sequence\"].apply(remove_AG)\n",
        "###End code here\n",
        "\n",
        "print(data.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label                sequence\n",
            "0      1  TTTGAATTGTAGGTGTCCTGCT\n",
            "1      1  TATTTTTTAAAGAACTGGAAGA\n",
            "2      1  TTTCTTTTTCAGATGAAGAATG\n",
            "3      1  TATTAATTTCAGTTTGGTTGTT\n",
            "4      1  TAAAAATTTAAGTTCGTCCCGA\n",
            "   label              sequence\n",
            "0      1  TTTGAATTGTGTGTCCTGCT\n",
            "1      1  TATTTTTTAAAACTGGAAGA\n",
            "2      1  TTTCTTTTTCATGAAGAATG\n",
            "3      1  TATTAATTTCTTTGGTTGTT\n",
            "4      1  TAAAAATTTATTCGTCCCGA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZkQumNiu22E",
        "colab_type": "text"
      },
      "source": [
        "A trivial feature vector representation would be to replace each amino acid with a number, making the Machine Learning aware about each amino acid at each position in the DNA context sequence. The following method maps a DNA sequence `x`to a Python list with a number for each amino acid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA5jYH1su22F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DNA_int_encoding(x):\n",
        "    encoding = []\n",
        "    for nuc in x:\n",
        "        if nuc == 'A':\n",
        "            encoding.append(0)\n",
        "        elif nuc == 'C':\n",
        "            encoding.append(1)\n",
        "        elif nuc == 'G':\n",
        "            encoding.append(2)\n",
        "        elif nuc == 'T':\n",
        "            encoding.append(3)\n",
        "        else:\n",
        "            print(\"Found non-nucleotide in %s\"%x)\n",
        "    return encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MJXJBj0u22I",
        "colab_type": "text"
      },
      "source": [
        "*Apply this function on the `sequence` column in the `data` DataFrame to create a Series with feature vectors (write the resulting feature vectors to a variable called `data_features_int_encoding`:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFRdEtCeu22J",
        "colab_type": "code",
        "outputId": "3594dcd1-58ab-4f91-c7ad-171f6543bcd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "###Start code here\n",
        "data_features_int_encoding = data[\"sequence\"].apply(DNA_int_encoding)\n",
        "###End code here\n",
        "\n",
        "data_features_int_encoding.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [3, 3, 3, 2, 0, 0, 3, 3, 2, 3, 2, 3, 2, 3, 1, ...\n",
              "1    [3, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 1, 3, 2, ...\n",
              "2    [3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 0, 3, 2, 0, 0, ...\n",
              "3    [3, 0, 3, 3, 0, 0, 3, 3, 3, 1, 3, 3, 3, 2, 2, ...\n",
              "4    [3, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 1, 2, 3, ...\n",
              "Name: sequence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVDjAmKZu22P",
        "colab_type": "text"
      },
      "source": [
        "Next we put these feature vectors back in a Pandas DataFrame as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztKXm9yYu22Q",
        "colab_type": "code",
        "outputId": "5f7f0a9b-b6bb-4548-a63a-d4161debe5c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data_features_int_encoding = pd.DataFrame(data_features_int_encoding.tolist())\n",
        "\n",
        "data_features_int_encoding.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19\n",
              "0  3  3  3  2  0  0  3  3  2  3   2   3   2   3   1   1   3   2   1   3\n",
              "1  3  0  3  3  3  3  3  3  0  0   0   0   1   3   2   2   0   0   2   0\n",
              "2  3  3  3  1  3  3  3  3  3  1   0   3   2   0   0   2   0   0   3   2\n",
              "3  3  0  3  3  0  0  3  3  3  1   3   3   3   2   2   3   3   2   3   3\n",
              "4  3  0  0  0  0  0  3  3  3  0   3   3   1   2   3   1   1   1   2   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0573K2rRu22W",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the generalization performance of a logisitc regression model with hyperparameters $C=0.1$ on the data set `data_features_int_encoding` using 10-fold cross-validation. \n",
        "\n",
        "*Apply the `cross_val_score()` function to compute an accuracy score for each fold in the CV:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc7J8SrIu22X",
        "colab_type": "code",
        "outputId": "7b9cd677-6449-4a5b-aa8b-0b1017d97ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# solution!!\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "###Start code here\n",
        "model = LogisticRegression(C=0.1)\n",
        "scores = cross_val_score(model,data_features_int_encoding,data.label,cv=10)\n",
        "###Start code here\n",
        "\n",
        "print(np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9253658536585366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0olCEtYau22e",
        "colab_type": "text"
      },
      "source": [
        "Next we load an independent test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv_NJz5Uu22g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554/master/practicum/3._Classification/acceptor_sites_dataset_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj9SshLnu22l",
        "colab_type": "text"
      },
      "source": [
        "*Compute the feature vectors for the test set:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtuUX8K8u22m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Start code here (try to use just one line of code)\n",
        "data_test_features_int_encoding = pd.DataFrame(data_test[\"sequence\"].apply(remove_AG).apply(DNA_int_encoding).tolist())\n",
        "###Start code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9SWqTScu22u",
        "colab_type": "text"
      },
      "source": [
        "*Fit a logistic regression model on the train set.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHuDj5xsu22v",
        "colab_type": "code",
        "outputId": "dd7eac53-e09c-4311-cd45-3b4f992fe244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "###Start code here\n",
        "model.fit(data_features_int_encoding,data.label)\n",
        "###End code here"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_gu0seZu221",
        "colab_type": "text"
      },
      "source": [
        "*Make model predictions for the test set.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzX1UJqlu222",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Start code here\n",
        "predictions = model.predict(data_test_features_int_encoding)\n",
        "###End code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNIux5gFu227",
        "colab_type": "text"
      },
      "source": [
        "Scikit-learn offers many metrics to evaluate model predictions. These functions are contained in the `metrics` module of `sklearn`. \n",
        "\n",
        "*Can you find how to compute the accuracy of these predictions (use the `metrics`module)?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTFGB05gu228",
        "colab_type": "code",
        "outputId": "a14a9411-59ef-4ce2-90e7-d6a8c5ee959f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "###Start code here\n",
        "score_acc = metrics.accuracy_score(data_test.label,predictions)\n",
        "###End code here\n",
        "\n",
        "print(score_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9221014492753623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPu8YDA2u23D",
        "colab_type": "text"
      },
      "source": [
        "An accuracy above 90% seems like a good score. But is it? Let's consider a model that predicts class \"-1\" for all test points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kV1yMLOu23E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_zero = [-1]*len(data_test.label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efNP_I-Ju23I",
        "colab_type": "text"
      },
      "source": [
        "*What is the accuracy of these predictions?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmdBsSaou23K",
        "colab_type": "code",
        "outputId": "7489405b-4f85-42bc-f1b9-c21de0b4330f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Start code here\n",
        "score_acc = metrics.accuracy_score(data_test.label,predictions_zero)\n",
        "###End code here\n",
        "\n",
        "print(score_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9003623188405797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lZ3nJUPu23P",
        "colab_type": "text"
      },
      "source": [
        "So this should be a good score as well, even though we did not learn anything.\n",
        "\n",
        "For classification tasks where the classes are highly imbalanced accuracy is not a good metric to evaluate the generalization performance. In fact, if there are 0.1% \"AG\" dinucleotides in a genome that are true acceptor sites then a model that predicts class \"-1\" for each \"AG\" would have an accuracy of 99.9%.\n",
        "\n",
        "We have seen how a ROC curve plots the true positives rate against the false positives rate. Both these metrics focus on the positive class, in our case the true acceptor sites. These metrics are much more suitable to evalute the performance of models on tasks with highly imbalanced classes. To transform a ROC curve into one metric we can use the area under the curve (AUC). \n",
        "\n",
        "*What is the AUC score of the predictions computed by the linear regression model we fitted?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTjM_o7Iu23Q",
        "colab_type": "code",
        "outputId": "b747590f-108e-4050-88bc-92357b9d08bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Start code here\n",
        "score_auc = metrics.auc(data_test.label,predictions)\n",
        "###End code here\n",
        "\n",
        "print(score_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9003623188405797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbuR3_0Uu23V",
        "colab_type": "text"
      },
      "source": [
        "You should see a negative value. This is because to compute the AUC we need the predictions to be scores (a continuous value) rather than class labels (discrete values). \n",
        "\n",
        "For logistic regression these scores are the class probabilities predicted by the model. We can obtain them using the `predict_proba()` function of the `LogisticRegression` module as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMT2X0i7u23W",
        "colab_type": "code",
        "outputId": "3a263c00-4906-40d0-c0f4-895da46c215c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "predictions = model.predict_proba(data_test_features_int_encoding)\n",
        "\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.33015439 0.66984561]\n",
            " [0.44977258 0.55022742]\n",
            " [0.34876393 0.65123607]\n",
            " ...\n",
            " [0.99674001 0.00325999]\n",
            " [0.9820754  0.0179246 ]\n",
            " [0.982688   0.017312  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecMykZJcu23h",
        "colab_type": "text"
      },
      "source": [
        "The first and second column contain the predicted probabilities for class '-1' and '1' respectively. To compute the AUC we need to use the positive class probabilities. \n",
        "\n",
        "*What is the AUC now?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Zj60JBu23i",
        "colab_type": "code",
        "outputId": "ec7044f4-b9ce-4711-a307-648e6c9b50b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Start code here\n",
        "score_auc = metrics.auc(data_test.label,predictions[:,1])\n",
        "###End code here\n",
        "\n",
        "print(score_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.365258280739163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EudhUPu-u23o",
        "colab_type": "text"
      },
      "source": [
        "Is this good generalization performance?\n",
        "\n",
        "Transforming categorical features into ordered integers is maybe not a good idea as the nucleotides don't have any ordering. It is better to transform a categorical feature into one binary feature for each category (known as *one-hot* encoding). \n",
        "\n",
        "We can do this with the following function that again computes feature vectors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q62ik5Gyu23p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DNA_onehot_encoding(x):\n",
        "    encoding = []\n",
        "    for nuc in x:\n",
        "        if nuc == 'A':\n",
        "            encoding.extend([1,0,0,0])\n",
        "        elif nuc == 'C':\n",
        "            encoding.extend([0,1,0,0])\n",
        "        elif nuc == 'G':\n",
        "            encoding.extend([0,0,1,0])\n",
        "        elif nuc == 'T':\n",
        "            encoding.extend([0,0,0,1])\n",
        "        else:\n",
        "            encoding.extend([0,0,0,0])\n",
        "    return encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufn2ity1u23y",
        "colab_type": "text"
      },
      "source": [
        "*Create a Pandas DataFrame called `data_features_onehot_encoding` that contains the one-hot encoded features.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d61H88bFu23z",
        "colab_type": "code",
        "outputId": "d05b7ae8-7e35-42ba-a110-96dbdcd65c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "###Start code here\n",
        "data_features_onehot_encoding = pd.DataFrame(data[\"sequence\"].apply(DNA_onehot_encoding).tolist())\n",
        "###End code here\n",
        "\n",
        "data_features_onehot_encoding.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0   1   2   3   4   5   6   7   8   9   10  ...  69  70  71  72  73  74  75  76  77  78  79\n",
              "0   0   0   0   1   0   0   0   1   0   0   0  ...   0   1   0   0   1   0   0   0   0   0   1\n",
              "1   0   0   0   1   1   0   0   0   0   0   0  ...   0   0   0   0   0   1   0   1   0   0   0\n",
              "2   0   0   0   1   0   0   0   1   0   0   0  ...   0   0   0   0   0   0   1   0   0   1   0\n",
              "3   0   0   0   1   1   0   0   0   0   0   0  ...   0   1   0   0   0   0   1   0   0   0   1\n",
              "4   0   0   0   1   1   0   0   0   1   0   0  ...   1   0   0   0   0   1   0   1   0   0   0\n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJgd7t3T7x2j",
        "colab_type": "text"
      },
      "source": [
        "Now let's add interpretable feature names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nszf4267siU",
        "colab_type": "code",
        "outputId": "55dd8f56-6d02-4816-9607-ef4d21237e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "columns = []\n",
        "for i in range(-10,0,1):\n",
        "    for nuc in ['A','C','G','T']:\n",
        "        columns.append(\"%i_%s\"%(i,nuc))\n",
        "for i in range(1,11,1):\n",
        "    for nuc in ['A','C','G','T']:\n",
        "        columns.append(\"%i_%s\"%(i,nuc))       \n",
        "data_features_onehot_encoding.columns = columns\n",
        "data_features_onehot_encoding.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-10_A</th>\n",
              "      <th>-10_C</th>\n",
              "      <th>-10_G</th>\n",
              "      <th>-10_T</th>\n",
              "      <th>-9_A</th>\n",
              "      <th>-9_C</th>\n",
              "      <th>-9_G</th>\n",
              "      <th>-9_T</th>\n",
              "      <th>-8_A</th>\n",
              "      <th>-8_C</th>\n",
              "      <th>-8_G</th>\n",
              "      <th>-8_T</th>\n",
              "      <th>-7_A</th>\n",
              "      <th>-7_C</th>\n",
              "      <th>-7_G</th>\n",
              "      <th>-7_T</th>\n",
              "      <th>-6_A</th>\n",
              "      <th>-6_C</th>\n",
              "      <th>-6_G</th>\n",
              "      <th>-6_T</th>\n",
              "      <th>-5_A</th>\n",
              "      <th>-5_C</th>\n",
              "      <th>-5_G</th>\n",
              "      <th>-5_T</th>\n",
              "      <th>-4_A</th>\n",
              "      <th>-4_C</th>\n",
              "      <th>-4_G</th>\n",
              "      <th>-4_T</th>\n",
              "      <th>-3_A</th>\n",
              "      <th>-3_C</th>\n",
              "      <th>-3_G</th>\n",
              "      <th>-3_T</th>\n",
              "      <th>-2_A</th>\n",
              "      <th>-2_C</th>\n",
              "      <th>-2_G</th>\n",
              "      <th>-2_T</th>\n",
              "      <th>-1_A</th>\n",
              "      <th>-1_C</th>\n",
              "      <th>-1_G</th>\n",
              "      <th>-1_T</th>\n",
              "      <th>1_A</th>\n",
              "      <th>1_C</th>\n",
              "      <th>1_G</th>\n",
              "      <th>1_T</th>\n",
              "      <th>2_A</th>\n",
              "      <th>2_C</th>\n",
              "      <th>2_G</th>\n",
              "      <th>2_T</th>\n",
              "      <th>3_A</th>\n",
              "      <th>3_C</th>\n",
              "      <th>3_G</th>\n",
              "      <th>3_T</th>\n",
              "      <th>4_A</th>\n",
              "      <th>4_C</th>\n",
              "      <th>4_G</th>\n",
              "      <th>4_T</th>\n",
              "      <th>5_A</th>\n",
              "      <th>5_C</th>\n",
              "      <th>5_G</th>\n",
              "      <th>5_T</th>\n",
              "      <th>6_A</th>\n",
              "      <th>6_C</th>\n",
              "      <th>6_G</th>\n",
              "      <th>6_T</th>\n",
              "      <th>7_A</th>\n",
              "      <th>7_C</th>\n",
              "      <th>7_G</th>\n",
              "      <th>7_T</th>\n",
              "      <th>8_A</th>\n",
              "      <th>8_C</th>\n",
              "      <th>8_G</th>\n",
              "      <th>8_T</th>\n",
              "      <th>9_A</th>\n",
              "      <th>9_C</th>\n",
              "      <th>9_G</th>\n",
              "      <th>9_T</th>\n",
              "      <th>10_A</th>\n",
              "      <th>10_C</th>\n",
              "      <th>10_G</th>\n",
              "      <th>10_T</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   -10_A  -10_C  -10_G  -10_T  -9_A  -9_C  ...  9_G  9_T  10_A  10_C  10_G  10_T\n",
              "0      0      0      0      1     0     0  ...    0    0     0     0     0     1\n",
              "1      0      0      0      1     1     0  ...    1    0     1     0     0     0\n",
              "2      0      0      0      1     0     0  ...    0    1     0     0     1     0\n",
              "3      0      0      0      1     1     0  ...    0    1     0     0     0     1\n",
              "4      0      0      0      1     1     0  ...    1    0     1     0     0     0\n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfAOG8SBu24E",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the generalization performance of a logisitc regression model with hyperparameters $C=0.1$ on the data set `data_features_onehot_encoding` using 10-fold cross-validation. \n",
        "The `cross_val_score()` has a function parameter called `scoring` that allows you to set different scoring metrics.\n",
        "\n",
        "*Use the `cross_val_score()` function to compute the mean AUC of the CV-scores.* \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq2cZVNSu24F",
        "colab_type": "code",
        "outputId": "393f89ec-8e71-46e8-95f1-447a623b20bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = LogisticRegression(C=0.1)\n",
        "\n",
        "###Start code here\n",
        "score_acc = np.mean(cross_val_score(model,data_features_onehot_encoding,data.label,cv=10,scoring=\"roc_auc\"))\n",
        "###End code here\n",
        "\n",
        "print(score_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.365258280739163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqh-I3zuu24L",
        "colab_type": "text"
      },
      "source": [
        "*What is the AUC on `data_test`?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeCkxuubu24M",
        "colab_type": "code",
        "outputId": "160673dd-73f6-4a4f-87d9-d4b5eba8e77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Start code here\n",
        "data_test_features_onehot_encoding = pd.DataFrame(data_test[\"sequence\"].apply(remove_AG).apply(DNA_onehot_encoding).tolist())\n",
        "model.fit(data_features_onehot_encoding,data.label)\n",
        "predictions = model.predict_proba(data_test_features_onehot_encoding)\n",
        "score_auc = metrics.auc(data_test.label,predictions[:,1])\n",
        "###Start code here\n",
        "\n",
        "print(score_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9867797540208135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w-jdU-gu24Q",
        "colab_type": "text"
      },
      "source": [
        "Is this close to what your CV is telling you?\n",
        "\n",
        "We have used hyperparameter $C=0.1$ for the logistic regression model. \n",
        "\n",
        "*Is there a better value for this regularization parameter (use `GridSearchCV`)?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B63LA0zwu24S",
        "colab_type": "code",
        "outputId": "3b458d76-cc52-4770-e722-264c993e9bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "search_space = [0.001,0.01,0.1,1,10,100]\n",
        "\n",
        "###Start code here\n",
        "params = dict(C=search_space)\n",
        "grid_search = GridSearchCV(model, param_grid=params)\n",
        "grid_search.fit(data_features_onehot_encoding,data.label)\n",
        "###End code here\n",
        "\n",
        "print(grid_search.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjoFP1_bu24W",
        "colab_type": "text"
      },
      "source": [
        "*What is the 10-CV AUC performance with this value for $C$?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWxVj0hRu24X",
        "colab_type": "code",
        "outputId": "d8036e6e-2ecd-411f-a8a4-438274d5123a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Start code here\n",
        "model = LogisticRegression(C=1)\n",
        "score_auc = np.mean(cross_val_score(model,data_features_onehot_encoding,data.label,cv=10,scoring=\"roc_auc\"))\n",
        "###Start code here\n",
        "\n",
        "print(score_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9847463891516872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytpwmh2wu24c",
        "colab_type": "text"
      },
      "source": [
        "*What is the AUC performance on the test set for this value of $C$?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5906bHvu24d",
        "colab_type": "code",
        "outputId": "05dcc76b-77cf-4c7a-f774-59ed25247af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Start code here\n",
        "model.fit(data_features_onehot_encoding,data.label)\n",
        "predictions = model.predict_proba(data_test_features_onehot_encoding)\n",
        "score_auc = metrics.auc(data_test.label,predictions[:,1])\n",
        "###End code here\n",
        "\n",
        "print(score_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9532599840418435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "wRe1CLnUu24l",
        "colab_type": "text"
      },
      "source": [
        "Is this closer to the AUC you computed using 10-CV?\n",
        "\n",
        "Let's see how the model is making predictions (what patterns it extracted). In scikit-learn a fitted model has its modelparameters stored in `.coef_[0]`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f-NBEUt4AjE",
        "colab_type": "code",
        "outputId": "e8be18bb-2df7-41f8-9830-de771fa86b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(model.coef_[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.47913801 -0.21734157 -0.84815424  0.58622429  0.32255299 -0.38610416\n",
            " -0.73300594  0.79642359  0.43271421 -0.17206379 -0.82147414  0.5606902\n",
            "  0.11079628 -0.43093542 -0.31934691  0.63935255  0.86601068 -1.25349266\n",
            " -0.63738888  1.02473735 -0.11861092  0.06926326 -0.70450688  0.75372103\n",
            " -0.4718082  -0.6467675  -0.91722143  2.03566361 -1.27747723 -0.55827664\n",
            " -0.8625858   2.69820616 -0.11954326 -0.47204416 -0.84161892  1.43307283\n",
            " -0.64123723  2.05912016 -1.72034224  0.3023258   0.44369177 -0.72487884\n",
            "  1.11200797 -0.83095441 -0.07735498 -0.10416085  0.25928459 -0.07790228\n",
            "  0.03041843  0.1905419   0.2637964  -0.48489024 -0.32530546  0.44472124\n",
            "  0.26691915 -0.38646844 -0.66201988  0.57906414  0.50459143 -0.42176919\n",
            " -0.23317418  0.42568974  0.46338059 -0.65602966 -0.62006953  0.33864329\n",
            "  0.587697   -0.30640428 -0.14253564  0.225374    0.3280646  -0.41103648\n",
            " -0.07642458  0.51808758 -0.30303357 -0.13876294 -0.57864226  0.116347\n",
            "  0.69097627 -0.22881452]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdPAICuc4NWT",
        "colab_type": "text"
      },
      "source": [
        "For logistic regression this is one modelparameter for each feature (plus the interecept, which is not in `.coef_[0]`). \n",
        "\n",
        "Recall that for logistic regression a prediction is made by multiplying each fitted modelparameter with the corresponding feature, summing them and then squeezing this sum between 0 and 1 through the logistic function. Since all features have values 0 or 1 the modelparameter values indicate the importance of a feature during prediction.\n",
        "\n",
        "For plotting we will put the feature names and modelparameter values in a new DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mnte18-u242",
        "colab_type": "code",
        "outputId": "9195102a-1fec-4acb-f4e4-4bdf5aabeb72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "F_importances = []\n",
        "for feature_name, modelparameter in zip(data_features_onehot_encoding.columns,model.coef_[0]):\n",
        "    F_importances.append([feature_name,modelparameter])\n",
        "F_importances = pd.DataFrame(F_importances,columns=[\"feature_name\",\"importance\"])\n",
        "F_importances.head()    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_name</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-10_A</td>\n",
              "      <td>0.479138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-10_C</td>\n",
              "      <td>-0.217342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-10_G</td>\n",
              "      <td>-0.848154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-10_T</td>\n",
              "      <td>0.586224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9_A</td>\n",
              "      <td>0.322553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  feature_name  importance\n",
              "0        -10_A    0.479138\n",
              "1        -10_C   -0.217342\n",
              "2        -10_G   -0.848154\n",
              "3        -10_T    0.586224\n",
              "4         -9_A    0.322553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SwWB_xQ8w8g",
        "colab_type": "text"
      },
      "source": [
        "*Use the Seaborn `.barplot()` method to plot this DataFrame:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_thWFCY894M",
        "colab_type": "code",
        "outputId": "3e134bc3-6735-41a9-f1eb-da0422bea3a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(18,8))\n",
        "\n",
        "###Start code here\n",
        "chart = sns.barplot(x=\"feature_name\",y=\"importance\",data=F_importances)\n",
        "###End code here\n",
        "\n",
        "chart.set_xticklabels(chart.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0N9sbu79xoi",
        "colab_type": "text"
      },
      "source": [
        "*Create a plot that looks like this:*\n",
        "\n",
        "![plot](https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554/master/practicum/3._Classification/AG_plot.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntsnD5Kwu25B",
        "colab_type": "code",
        "outputId": "710b4b4d-ebaa-4f8c-fc1f-1873b322dfe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "def get_nuc(x):\n",
        "    return(x.split(\"_\")[1])\n",
        "\n",
        "def get_position(x):\n",
        "    if x.split(\"_\")[0] == \"A\": return 0\n",
        "    if x.split(\"_\")[0] == \"G\": return 0\n",
        "    return(int(x.split(\"_\")[0]))\n",
        "\n",
        "F_importances[\"nuc\"] = F_importances[\"feature_name\"].apply(get_nuc)\n",
        "F_importances[\"position\"] = F_importances[\"feature_name\"].apply(get_position)\n",
        "\n",
        "print(F_importances.head())\n",
        "\n",
        "plt.figure(figsize=(18,8))\n",
        "sns.barplot(x=\"position\",y=\"importance\",hue=\"nuc\",data=F_importances)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_name</th>\n",
              "      <th>importance</th>\n",
              "      <th>nuc</th>\n",
              "      <th>position</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-10_A</td>\n",
              "      <td>0.479138</td>\n",
              "      <td>A</td>\n",
              "      <td>-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-10_C</td>\n",
              "      <td>-0.217342</td>\n",
              "      <td>C</td>\n",
              "      <td>-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-10_G</td>\n",
              "      <td>-0.848154</td>\n",
              "      <td>G</td>\n",
              "      <td>-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-10_T</td>\n",
              "      <td>0.586224</td>\n",
              "      <td>T</td>\n",
              "      <td>-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9_A</td>\n",
              "      <td>0.322553</td>\n",
              "      <td>A</td>\n",
              "      <td>-9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  feature_name  importance nuc  position\n",
              "0        -10_A    0.479138   A       -10\n",
              "1        -10_C   -0.217342   C       -10\n",
              "2        -10_G   -0.848154   G       -10\n",
              "3        -10_T    0.586224   T       -10\n",
              "4         -9_A    0.322553   A        -9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5haGvAHu25c",
        "colab_type": "code",
        "outputId": "2304758e-c9b0-4f75-8588-2e2b125ca40a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f39997ac320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1uafole2Y-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}