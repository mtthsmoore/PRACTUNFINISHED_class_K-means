{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Philosopher:400,700,400italic,700italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>\n",
       "\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "\n",
       "#notebook_panel { /* main background */\n",
       "    background: #888;\n",
       "    color: #f6f6f6;\n",
       "}\n",
       "\n",
       "div.cell { /* set cell width to about 80 chars */\n",
       "}\n",
       "\n",
       "div #notebook { /* centre the content */\n",
       "    background: #fff; /* white background for content */\n",
       "    margin: auto;\n",
       "}\n",
       "\n",
       "#notebook li { /* More space between bullet points */\n",
       "margin-top:0.8em;\n",
       "}\n",
       "\n",
       "/* draw border around running cells */\n",
       "div.cell.border-box-sizing.code_cell.running {\n",
       "    border: 3px solid #111;\n",
       "}\n",
       "\n",
       "/* Put a solid color box around each cell and its output, visually linking them together */\n",
       "div.cell.code_cell {\n",
       "    /*background-color: rgba(171,165,131,0.3); /*\n",
       "    border-radius: 10px; /* rounded borders */\n",
       "    padding: 1em;\n",
       "    /*margin-top: 1em;*/\n",
       "}\n",
       "\n",
       "div.text_cell_render{\n",
       "    font-family: 'Open Sans', Helvetica;\n",
       "    line-height: 140%;\n",
       "    font-size: 105%;\n",
       "    /*margin-top:15px;*/\n",
       "    margin-bottom:8px;\n",
       "    text-align:justify;\n",
       "}\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Open Sans',sans-serif;\n",
       "    font-weight: 100;\n",
       "    font-size: 30pt;\n",
       "    line-height: 100%;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    font-weight: 700;\n",
       "    font-size: 24pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(171,165,131);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}    \n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    margin-top:12px;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: italic;\n",
       "    color: rgb(95,92,72);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {\n",
       "    font-family: 'Alegreya Sans', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 16pt;\n",
       "    color: grey;\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 {\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 10pt;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".CodeMirror{\n",
       "        font-family: \"PT Mono\";\n",
       "        font-size: 100%;\n",
       "}\n",
       "\n",
       ".output_area {\n",
       "\tmargin-top:20px;\n",
       "}\n",
       "\n",
       ".output_stderr {\n",
       "\tdisplay:none;\n",
       "\t}\n",
       "\n",
       ".output_subarea {\n",
       "\tdisplay: block;\n",
       "    margin: 0 auto;\n",
       "}\n",
       "\n",
       ".output_png img {\n",
       "    display: block;\n",
       "    margin-left: auto;\n",
       "    margin-right: auto;\n",
       "}\n",
       "\n",
       ".prompt {\n",
       "\tvisible: false;\n",
       "\t}\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "compomics_import = imp.load_source('compomics_import', '../../compomics_import.py')\n",
    "from IPython.core.display import HTML\n",
    "css_file = '../../my.css'\n",
    "HTML(open(css_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical session we will build a classification model for gene splice site prediction. It is a problem arising in computational gene finding and concerns the recognition of splice sites that mark the boundaries between exons and introns in eukaryotes. Introns are spliced from premature mRNAs after transcription. The vast majority of splice sites are characterized by the presence of specific dimers on the intronic side of the splice site: GT for donor and AG for acceptor sites. Yet, only about 0.1-1% of all GT and AG occurrences in the genome represent true splice sites. \n",
    "\n",
    "Load the acceptor site training data set *acceptor_sites_dataset_train.csv* in a Pandas DataFrame called `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution!!\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"acceptor_sites_dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first 5 rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TTTGAATTGTAGGTGTCCTGCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TATTTTTTAAAGAACTGGAAGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TTTCTTTTTCAGATGAAGAATG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>TATTAATTTCAGTTTGGTTGTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>TAAAAATTTAAGTTCGTCCCGA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                sequence\n",
       "0      1  TTTGAATTGTAGGTGTCCTGCT\n",
       "1      1  TATTTTTTAAAGAACTGGAAGA\n",
       "2      1  TTTCTTTTTCAGATGAAGAATG\n",
       "3      1  TATTAATTTCAGTTTGGTTGTT\n",
       "4      1  TAAAAATTTAAGTTCGTCCCGA"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution!!\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only two columns. The column \"sequence\" contains a DNA sequence with lenght 22. The nucleotides at positions 11 and 12 in the sequence are always \"A\" and \"G\" respectively, so these positions are candidate gene acceptor sites. The column \"target\" indicates the class: 1 for \"is acceptor site\" and -1 for \"is not acceptor site\". The goal is to predict the target from the local context sequence of the candidate acceptor site. Let's see how many data points belong to each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1503\n",
       " 1     145\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Machine Learning algorithms we well apply we cannot use the DNA sequences as input. We will need to compute features from the DNA sequences that will allow us to detect true acceptor sites, a process known as **feature engineering**. \n",
    "\n",
    "In the first practicum we have seen the Pandas `apply()` function that allows us the process the values in a DataFrame column to create a new column. We will apply this function to compute feature vectors from the `sequence` column in the `data` DataFrame.  \n",
    "\n",
    "First we need to convert the DNA sequence into features. We don't need to compute features from the middle AG dinculeotide in the local context sequence. Why?\n",
    "\n",
    "Let's remove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                sequence\n",
      "0      1  TTTGAATTGTAGGTGTCCTGCT\n",
      "1      1  TATTTTTTAAAGAACTGGAAGA\n",
      "2      1  TTTCTTTTTCAGATGAAGAATG\n",
      "3      1  TATTAATTTCAGTTTGGTTGTT\n",
      "4      1  TAAAAATTTAAGTTCGTCCCGA\n",
      "   label              sequence\n",
      "0      1  TTTGAATTGTGTGTCCTGCT\n",
      "1      1  TATTTTTTAAAACTGGAAGA\n",
      "2      1  TTTCTTTTTCATGAAGAATG\n",
      "3      1  TATTAATTTCTTTGGTTGTT\n",
      "4      1  TAAAAATTTATTCGTCCCGA\n"
     ]
    }
   ],
   "source": [
    "def remove_AG(x):\n",
    "    return x[0:10]+x[12:22]\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "data[\"sequence\"] = data[\"sequence\"].apply(remove_AG)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the following function do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNA_int_encoding(x):\n",
    "    encoding = []\n",
    "    for nuc in x:\n",
    "        if nuc == 'A':\n",
    "            encoding.append(0)\n",
    "        elif nuc == 'C':\n",
    "            encoding.append(1)\n",
    "        elif nuc == 'G':\n",
    "            encoding.append(2)\n",
    "        elif nuc == 'T':\n",
    "            encoding.append(3)\n",
    "        else:\n",
    "            print(\"Found non-nucleotide in %s\"%x)\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use this function on the `sequence` column in the `data` DataFrame to create a Series with feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [3, 3, 3, 2, 0, 0, 3, 3, 2, 3, 2, 3, 2, 3, 1, ...\n",
       "1    [3, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 1, 3, 2, ...\n",
       "2    [3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 0, 3, 2, 0, 0, ...\n",
       "3    [3, 0, 3, 3, 0, 0, 3, 3, 3, 1, 3, 3, 3, 2, 2, ...\n",
       "4    [3, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 1, 2, 3, ...\n",
       "Name: sequence, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features_int_encoding = data[\"sequence\"].apply(DNA_int_encoding)\n",
    "\n",
    "data_features_int_encoding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we put these feature vectors back in a Pandas DataFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  \\\n",
       "0   3   3   3   2   0   0   3   3   2   3   2   3   2   3   1   1   3   2   1   \n",
       "1   3   0   3   3   3   3   3   3   0   0   0   0   1   3   2   2   0   0   2   \n",
       "2   3   3   3   1   3   3   3   3   3   1   0   3   2   0   0   2   0   0   3   \n",
       "3   3   0   3   3   0   0   3   3   3   1   3   3   3   2   2   3   3   2   3   \n",
       "4   3   0   0   0   0   0   3   3   3   0   3   3   1   2   3   1   1   1   2   \n",
       "\n",
       "   19  \n",
       "0   3  \n",
       "1   0  \n",
       "2   2  \n",
       "3   3  \n",
       "4   0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features_int_encoding = pd.DataFrame(data_features_int_encoding.tolist())\n",
    "\n",
    "data_features_int_encoding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does `data_features_int_encoding` contain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the generalization performance of a logisitc regression model with hyperparameters $C=0.1$ on the data set `data_features_int_encoding` using 10-fold cross-validation. Use the `cross_val_score()` function to compute the mean accuracy of the CV-scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fe703f91e6d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# solution!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"
     ]
    }
   ],
   "source": [
    "# solution!!\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "model = LogisticRegression(C=0.1)\n",
    "print(np.mean(cross_val_score(model,data_features_int_encoding,data.label,cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this number mean?\n",
    "\n",
    "Load the acceptor site test data set *acceptor_sites_dataset_test.csv* in a Pandas DataFrame called `data_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"acceptor_sites_dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to compute the same feature vectors for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution !!!\n",
    "\n",
    "data_test[\"sequence\"] = data_test[\"sequence\"].apply(remove_AG)\n",
    "\n",
    "data_test_features_int_encoding = data_test[\"sequence\"].apply(DNA_int_encoding)\n",
    "data_test_features_int_encoding = pd.DataFrame(data_test_features_int_encoding.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit a logistic regression model on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data_features_int_encoding,data.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the class labels for the third part (the test set) using this model we can use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(data_test_features_int_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn offers many metrics to evaluate model predictions. These functions are contained in the `metrics` module of `sklearn`. Can you find how to compute the accuracy of these predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution!!\n",
    "from sklearn import metrics\n",
    "\n",
    "print metrics.accuracy_score(data_test.label,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy above 90% seems like a good score. But is it? Let's consider a model that predicts class \"-1\" for all test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_zero = [-1]*len(data_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the accuracy of these predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution !!\n",
    "print metrics.accuracy_score(data_test.label,predictions_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this should be a good score as well, even though we did not learn anything.\n",
    "\n",
    "For classification tasks where the classes are highly imbalanced accuracy is not a good metric to evaluate the generalization performance. In fact, if there are 0.1% AG dinucleotides in a genome that are true acceptor sites then a model that predicts class \"-1\" for each AG would have an accuracy of 99.9%.\n",
    "\n",
    "We have seen how a ROC curve plots the true positives rate against the false positives rate. Both these metrics focus on the positive class, in our case the true acceptor sites. These metrics are much more suitable to evalute the performance of models on tasks with highly imbalanced classes. To transform a ROC curve into one metric we can use the area under the curve (AUC). \n",
    "\n",
    "What is the AUC score of the predictions computed by the linear regression model we fitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution !!\n",
    "print metrics.auc(data_test.label,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a negative value. This is because to compute the AUC we need the predictions to be scores (a continuous value) rather than class labels (discrete values). \n",
    "\n",
    "For logistic regression these scores are the class probabilities predicted by the model. We can obtain them using the `predict_proba()` function of the `LogisticRegression` module as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(data_test_features_int_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does variable `predictions` contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution !!\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and second column contains the predicted probabilities for class '-1' and '1' respectively. To compute the AUC we need to use the positive class probabilities. What is the AUC now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution !!\n",
    "print metrics.auc(data_test.label,predictions[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this good generalization performance?\n",
    "\n",
    "Transforming categorical features into ordered integers is maybe not a good idea as the nucleotides don't have any ordering. It is better to transform a categorical feature into one binary feature for each category (known as *one-hot* encoding. \n",
    "\n",
    "We can do this with the following function that again computes feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNA_onehot_encoding(x):\n",
    "    encoding = []\n",
    "    for nuc in x:\n",
    "        if nuc == 'A':\n",
    "            encoding.extend([1,0,0,0])\n",
    "        elif nuc == 'C':\n",
    "            encoding.extend([0,1,0,0])\n",
    "        elif nuc == 'G':\n",
    "            encoding.extend([0,0,1,0])\n",
    "        elif nuc == 'T':\n",
    "            encoding.extend([0,0,0,1])\n",
    "        else:\n",
    "            encoding.extend([0,0,0,0])\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas DataFrame called `data_features_onehot_encoding` that contains the *one-hot* encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features_onehot_encoding = pd.DataFrame(data[\"sequence\"].apply(DNA_onehot_encoding).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features_onehot_encoding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask about features for AG...\n",
    "#now build a final model that you can use in production\n",
    "#investigate feature importances\n",
    "#given this analsis, is the test set still unseen data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the generalization performance of a logisitc regression model with hyperparameters $C=0.1$ on the data set `data_features_onehot_encoding` using 10-fold cross-validation. Use the `cross_val_score()` function to compute the mean AUC of the CV-scores. The `cross_val_score()` has a function parameter called `scoring` that you will not to use to replace the *accuracy* metric with the *AUC* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.1)\n",
    "print np.mean(cross_val_score(model,data_features_onehot_encoding,data.label,cv=10,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the AUC on `data_test`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_features_onehot_encoding = pd.DataFrame(data_test[\"sequence\"].apply(DNA_onehot_encoding).tolist())\n",
    "\n",
    "model.fit(data_features_onehot_encoding,data.label)\n",
    "\n",
    "predictions = model.predict_proba(data_test_features_onehot_encoding)\n",
    "print \"AUC=%.2f\" % metrics.auc(data_test.label,predictions[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this close to what your CV is telling you?\n",
    "\n",
    "We have used hyperparameter $C=0.1$ for the logistic regression model. Is there a better value for this regularization parameter (use `GridSearchCV`)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution !!\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "search_space = [0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "params = dict(C=search_space)\n",
    "grid_search = GridSearchCV(model, param_grid=params)\n",
    "\n",
    "grid_search.fit(data_features_onehot_encoding,data.label)\n",
    "\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the 10-CV AUC performance with this value for $C$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1)\n",
    "print np.mean(cross_val_score(model,data_features_onehot_encoding,data.label,cv=10,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the AUC performance on the test set for this value of $C$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data_features_onehot_encoding,data.label)\n",
    "\n",
    "predictions = model.predict_proba(data_test_features_onehot_encoding)\n",
    "print \"AUC=%.2f\" % metrics.auc(data_test.label,predictions[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Is this closer to the AUC you computed using 10-CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "\n",
    "for i in range(-10,0,1):\n",
    "    for nuc in ['A','C','G','T']:\n",
    "        columns.append(\"%i_%s\"%(i,nuc))\n",
    "for i in range(1,11,1):\n",
    "    for nuc in ['A','C','G','T']:\n",
    "        columns.append(\"%i_%s\"%(i,nuc))\n",
    "        \n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features_onehot_encoding.columns = columns\n",
    "data_features_onehot_encoding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data_features_onehot_encoding,data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_importances = []\n",
    "for feature_name,lr_coefficient in zip(data_features_onehot_encoding.columns,model.coef_[0]):\n",
    "    F_importances.append([feature_name,lr_coefficient])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_importances = pd.DataFrame(F_importances,columns=[\"feature_name\",\"importance\"])\n",
    "F_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nuc(x):\n",
    "    return(x.split(\"_\")[1])\n",
    "\n",
    "def get_position(x):\n",
    "    if x.split(\"_\")[0] == \"A\": return 0\n",
    "    if x.split(\"_\")[0] == \"G\": return 0\n",
    "    return(int(x.split(\"_\")[0]))\n",
    "\n",
    "F_importances[\"nuc\"] = F_importances[\"feature_name\"].apply(get_nuc)\n",
    "F_importances[\"position\"] = F_importances[\"feature_name\"].apply(get_position)\n",
    "\n",
    "F_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#sns.barplot(x=\"position\",y=\"importance\",data=F_importances[F_importances[\"nuc\"]==\"A\"])\n",
    "\n",
    "sns.factorplot(x=\"position\", y=\"importance\", hue=\"nuc\", data=F_importances, aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shorter(x):\n",
    "    return x[4:-4]\n",
    "\n",
    "data[\"sequence_10\"] = data[\"sequence\"].apply(make_shorter)\n",
    "data_test[\"sequence_10\"] = data_test[\"sequence\"].apply(make_shorter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features_onehot_encoding = pd.DataFrame(data[\"sequence_10\"].apply(DNA_onehot_encoding).tolist())\n",
    "data_test_features_onehot_encoding = pd.DataFrame(data_test[\"sequence_10\"].apply(DNA_onehot_encoding).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "search_space = [0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "params = dict(C=search_space)\n",
    "grid_search = GridSearchCV(model, param_grid=params)\n",
    "\n",
    "grid_search.fit(data_features_onehot_encoding,data.label)\n",
    "\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1)\n",
    "model.fit(data_features_onehot_encoding,data.label)\n",
    "\n",
    "predictions = model.predict_proba(data_test_features_onehot_encoding)\n",
    "print \"AUC=%.2f\" % metrics.auc(data_test.label,predictions[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
