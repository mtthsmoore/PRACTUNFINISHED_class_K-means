{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "2.1._Classification_solutions.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO24y4Jju21u",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhcU9Uucu21v",
        "colab_type": "text"
      },
      "source": [
        "Most eukaryotic genes undergo intron splicing events. These happen at the level of mRNA, after transcription and before translation. Pre-mRNA consists of exons, which are the proteincoding regions, and introns, which are the intervening sections in between. As a base rule, the spliceosome cuts out introns, retaining the consecutive exons to form mature mRNA. This mature mRNA is then translated to protein.\n",
        "\n",
        "In this practical you will build a classification model for gene splice site prediction from DNA sequences. The vast majority of splice sites are characterized by the presence of specific dimers on the intronic side of the splice site: \"GT\" for donor and \"AG\" for acceptor sites. Yet, only about 0.1-1% of all \"GT\" and \"AG\" occurrences in the genome represent true splice sites. \n",
        "\n",
        "We will focus on acceptor site prediction. You are given the following data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrdBiQtAu21v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554/master/practicum/3._Classification/acceptor_sites_dataset_train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lJt4Vopu212",
        "colab_type": "code",
        "outputId": "89a3fb31-c4f2-4112-f192-75a24d929d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>TTTGAATTGTAGGTGTCCTGCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>TATTTTTTAAAGAACTGGAAGA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>TTTCTTTTTCAGATGAAGAATG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>TATTAATTTCAGTTTGGTTGTT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>TAAAAATTTAAGTTCGTCCCGA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                sequence\n",
              "0      1  TTTGAATTGTAGGTGTCCTGCT\n",
              "1      1  TATTTTTTAAAGAACTGGAAGA\n",
              "2      1  TTTCTTTTTCAGATGAAGAATG\n",
              "3      1  TATTAATTTCAGTTTGGTTGTT\n",
              "4      1  TAAAAATTTAAGTTCGTCCCGA"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXgIExxtu216",
        "colab_type": "text"
      },
      "source": [
        "There are only two columns. The column \"sequence\" contains a local DNA context sequence that surrounds a candidate acceptor site (nucleotides at positions 11 and 12 in the sequence are always \"A\" and \"G\" respectively), so these positions are candidate gene acceptor sites. The column \"label\" indicates the class: 1 for \"is acceptor site\" and -1 for \"is not acceptor site\". The goal is to predict the target from the local context sequence of the candidate acceptor site. \n",
        "\n",
        "*How many sequences does the dataset contain for each class?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYhNkKz3u217",
        "colab_type": "code",
        "outputId": "658dd963-fbef-402c-8754-bed54ca0bde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "###Start code here\n",
        "data['label'].value_counts()\n",
        "###End code here"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    1503\n",
              " 1     145\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teweqTUhu21_",
        "colab_type": "text"
      },
      "source": [
        "Next, useful features need to be computed from the DNA sequences, a process known as **feature engineering**. \n",
        "\n",
        "The Pandas `.apply()` method allows us the process the values in a DataFrame column to create a new column. We will apply this function to compute feature vectors from the `sequence` column in the `data` DataFrame.  \n",
        "\n",
        "The \"AG\" in the middle of each context sequence is the same for both classes, i.e. it does not provide any discriminative information. So, We shouldn't compute features from the middle AG dinculeotide in the local context sequence.\n",
        "\n",
        "*Use the Pandas DataFrame `.apply()` method to remove the middle \"AG\" dinucleotides in the DNA sequences (don't create a new column):*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8ThMz7Su22A",
        "colab_type": "code",
        "outputId": "b385a889-a28a-4cf9-fa4e-b8817f475d1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "print(data.head())\n",
        "\n",
        "###Start code here\n",
        "def remove_AG(x):\n",
        "    return x[0:10]+x[12:22]\n",
        "\n",
        "data[\"sequence\"] = data[\"sequence\"].apply(remove_AG)\n",
        "###End code here\n",
        "\n",
        "print(data.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label                sequence\n",
            "0      1  TTTGAATTGTAGGTGTCCTGCT\n",
            "1      1  TATTTTTTAAAGAACTGGAAGA\n",
            "2      1  TTTCTTTTTCAGATGAAGAATG\n",
            "3      1  TATTAATTTCAGTTTGGTTGTT\n",
            "4      1  TAAAAATTTAAGTTCGTCCCGA\n",
            "   label              sequence\n",
            "0      1  TTTGAATTGTGTGTCCTGCT\n",
            "1      1  TATTTTTTAAAACTGGAAGA\n",
            "2      1  TTTCTTTTTCATGAAGAATG\n",
            "3      1  TATTAATTTCTTTGGTTGTT\n",
            "4      1  TAAAAATTTATTCGTCCCGA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZkQumNiu22E",
        "colab_type": "text"
      },
      "source": [
        "A trivial feature vector representation would be to replace each amino acid with a number, making the Machine Learning aware about each amino acid at each position in the DNA context sequence. The following method maps a DNA sequence `x`to a Python list with a number for each amino acid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA5jYH1su22F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DNA_int_encoding(x):\n",
        "    encoding = []\n",
        "    for nuc in x:\n",
        "        if nuc == 'A':\n",
        "            encoding.append(0)\n",
        "        elif nuc == 'C':\n",
        "            encoding.append(1)\n",
        "        elif nuc == 'G':\n",
        "            encoding.append(2)\n",
        "        elif nuc == 'T':\n",
        "            encoding.append(3)\n",
        "        else:\n",
        "            print(\"Found non-nucleotide in %s\"%x)\n",
        "    return encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MJXJBj0u22I",
        "colab_type": "text"
      },
      "source": [
        "*Apply this function on the `sequence` column in the `data` DataFrame to create a Series with feature vectors (write the resulting feature vectors to a variable called `data_features_int_encoding`:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFRdEtCeu22J",
        "colab_type": "code",
        "outputId": "37f0cdae-4059-4757-a858-1c785bbf7473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "###Start code here\n",
        "data_features_int_encoding = data[\"sequence\"].apply(DNA_int_encoding)\n",
        "###End code here\n",
        "\n",
        "data_features_int_encoding.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [3, 3, 3, 2, 0, 0, 3, 3, 2, 3, 2, 3, 2, 3, 1, ...\n",
              "1    [3, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 1, 3, 2, ...\n",
              "2    [3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 0, 3, 2, 0, 0, ...\n",
              "3    [3, 0, 3, 3, 0, 0, 3, 3, 3, 1, 3, 3, 3, 2, 2, ...\n",
              "4    [3, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 1, 2, 3, ...\n",
              "Name: sequence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVDjAmKZu22P",
        "colab_type": "text"
      },
      "source": [
        "Next we put these feature vectors back in a Pandas DataFrame as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztKXm9yYu22Q",
        "colab_type": "code",
        "outputId": "f3f7b814-9e9d-48c3-b7de-af97e3d3ee72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data_features_int_encoding = pd.DataFrame(data_features_int_encoding.tolist())\n",
        "\n",
        "data_features_int_encoding.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19\n",
              "0  3  3  3  2  0  0  3  3  2  3   2   3   2   3   1   1   3   2   1   3\n",
              "1  3  0  3  3  3  3  3  3  0  0   0   0   1   3   2   2   0   0   2   0\n",
              "2  3  3  3  1  3  3  3  3  3  1   0   3   2   0   0   2   0   0   3   2\n",
              "3  3  0  3  3  0  0  3  3  3  1   3   3   3   2   2   3   3   2   3   3\n",
              "4  3  0  0  0  0  0  3  3  3  0   3   3   1   2   3   1   1   1   2   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0573K2rRu22W",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the generalization performance of a logisitc regression model with hyperparameters $C=0.1$ on the data set `data_features_int_encoding` using 10-fold cross-validation. \n",
        "\n",
        "*Apply the `cross_val_score()` function to compute an accuracy score for each fold in the CV:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc7J8SrIu22X",
        "colab_type": "code",
        "outputId": "cd33921a-a976-45ef-a37b-316fc646ad3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# solution!!\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "###Start code here\n",
        "model = LogisticRegression(C=0.1)\n",
        "scores = cross_val_score(model,data_features_int_encoding,data.label,cv=10)\n",
        "###Start code here\n",
        "\n",
        "print(np.mean(scores))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9253658536585366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0olCEtYau22e",
        "colab_type": "text"
      },
      "source": [
        "Next we load an independent test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv_NJz5Uu22g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554/master/practicum/3._Classification/acceptor_sites_dataset_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj9SshLnu22l",
        "colab_type": "text"
      },
      "source": [
        "*Compute the feature vectors for the test set:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtuUX8K8u22m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Start code here (try to use just one line of code)\n",
        "data_test_features_int_encoding = pd.DataFrame(data_test[\"sequence\"].apply(remove_AG).apply(DNA_int_encoding).tolist())\n",
        "###Start code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9SWqTScu22u",
        "colab_type": "text"
      },
      "source": [
        "*Fit a logistic regression model on the train set.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHuDj5xsu22v",
        "colab_type": "code",
        "outputId": "846d3e3e-e2fa-44ca-c5e5-2f969ea1fb75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "###Start code here\n",
        "model.fit(data_features_int_encoding,data.label)\n",
        "###End code here"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_gu0seZu221",
        "colab_type": "text"
      },
      "source": [
        "*Make model predictions for the test set.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzX1UJqlu222",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Start code here\n",
        "predictions = model.predict(data_test_features_int_encoding)\n",
        "###End code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNIux5gFu227",
        "colab_type": "text"
      },
      "source": [
        "Scikit-learn offers many metrics to evaluate model predictions. These functions are contained in the `metrics` module of `sklearn`. \n",
        "\n",
        "*Can you find how to compute the accuracy of these predictions (use the `metrics`module)?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTFGB05gu228",
        "colab_type": "code",
        "outputId": "063c6c52-8c2d-4d72-e123-0f1b385555d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "###Start code here\n",
        "score_acc = metrics.accuracy_score(data_test.label,predictions)\n",
        "###End code here\n",
        "\n",
        "print(score_acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9221014492753623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPu8YDA2u23D",
        "colab_type": "text"
      },
      "source": [
        "An accuracy above 90% seems like a good score. But is it? Let's consider a model that predicts class \"-1\" for all test points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kV1yMLOu23E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_zero = [-1]*len(data_test.label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efNP_I-Ju23I",
        "colab_type": "text"
      },
      "source": [
        "*What is the accuracy of these predictions?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmdBsSaou23K",
        "colab_type": "code",
        "outputId": "3068d950-09da-4c57-c97b-48845e61f4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Start code here\n",
        "score_acc = metrics.accuracy_score(data_test.label,predictions_zero)\n",
        "###End code here\n",
        "\n",
        "print(score_acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9003623188405797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lZ3nJUPu23P",
        "colab_type": "text"
      },
      "source": [
        "So this should be a good score as well, even though we did not learn anything.\n",
        "\n",
        "For classification tasks where the classes are highly imbalanced accuracy is not a good metric to evaluate the generalization performance. In fact, if there are 0.1% \"AG\" dinucleotides in a genome that are true acceptor sites then a model that predicts class \"-1\" for each \"AG\" would have an accuracy of 99.9%.\n",
        "\n",
        "We have seen how a ROC curve plots the true positives rate against the false positives rate. Both these metrics focus on the positive class, in our case the true acceptor sites. These metrics are much more suitable to evalute the performance of models on tasks with highly imbalanced classes. To transform a ROC curve into one metric we can use the area under the curve (AUC). \n",
        "\n",
        "*What is the AUC score of the predictions computed by the linear regression model we fitted?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTjM_o7Iu23Q",
        "colab_type": "code",
        "outputId": "ea1be81c-ac2c-4619-fe4f-ac03a8005cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Start code here\n",
        "score_auc = metrics.auc(data_test.label,predictions)\n",
        "###End code here\n",
        "\n",
        "print(score_acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbuR3_0Uu23V",
        "colab_type": "text"
      },
      "source": [
        "You should see a negative value. This is because to compute the AUC we need the predictions to be scores (a continuous value) rather than class labels (discrete values). \n",
        "\n",
        "For logistic regression these scores are the class probabilities predicted by the model. We can obtain them using the `predict_proba()` function of the `LogisticRegression` module as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMT2X0i7u23W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict_proba(data_test_features_int_encoding)\n",
        "\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecMykZJcu23h",
        "colab_type": "text"
      },
      "source": [
        "The first and second column contain the predicted probabilities for class '-1' and '1' respectively. To compute the AUC we need to use the positive class probabilities. \n",
        "\n",
        "*What is the AUC now?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Zj60JBu23i",
        "colab_type": "code",
        "outputId": "28f8007e-fe3a-4bdc-953c-492899ab338e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Start code here\n",
        "score_auc = metrics.auc(data_test.label,predictions[:,1])\n",
        "###End code here\n",
        "\n",
        "print(score_auc)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.365258280739163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EudhUPu-u23o",
        "colab_type": "text"
      },
      "source": [
        "Is this good generalization performance?\n",
        "\n",
        "Transforming categorical features into ordered integers is maybe not a good idea as the nucleotides don't have any ordering. It is better to transform a categorical feature into one binary feature for each category (known as *one-hot* encoding). \n",
        "\n",
        "We can do this with the following function that again computes feature vectors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q62ik5Gyu23p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DNA_onehot_encoding(x):\n",
        "    encoding = []\n",
        "    for nuc in x:\n",
        "        if nuc == 'A':\n",
        "            encoding.extend([1,0,0,0])\n",
        "        elif nuc == 'C':\n",
        "            encoding.extend([0,1,0,0])\n",
        "        elif nuc == 'G':\n",
        "            encoding.extend([0,0,1,0])\n",
        "        elif nuc == 'T':\n",
        "            encoding.extend([0,0,0,1])\n",
        "        else:\n",
        "            encoding.extend([0,0,0,0])\n",
        "    return encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufn2ity1u23y",
        "colab_type": "text"
      },
      "source": [
        "*Create a Pandas DataFrame called `data_features_onehot_encoding` that contains the one-hot encoded features.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d61H88bFu23z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Start code here\n",
        "data_features_onehot_encoding = pd.DataFrame(data[\"sequence\"].apply(DNA_onehot_encoding).tolist())\n",
        "###End code here\n",
        "\n",
        "data_features_onehot_encoding.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJgd7t3T7x2j",
        "colab_type": "text"
      },
      "source": [
        "Now let's add interpretable feature names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nszf4267siU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "1b0e44b0-601f-4b4f-abec-421d2635a912"
      },
      "source": [
        "columns = []\n",
        "for i in range(-10,0,1):\n",
        "    for nuc in ['A','C','G','T']:\n",
        "        columns.append(\"%i_%s\"%(i,nuc))\n",
        "for i in range(1,11,1):\n",
        "    for nuc in ['A','C','G','T']:\n",
        "        columns.append(\"%i_%s\"%(i,nuc))       \n",
        "data_features_onehot_encoding.columns = columns\n",
        "data_features_onehot_encoding.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-10_A</th>\n",
              "      <th>-10_C</th>\n",
              "      <th>-10_G</th>\n",
              "      <th>-10_T</th>\n",
              "      <th>-9_A</th>\n",
              "      <th>-9_C</th>\n",
              "      <th>-9_G</th>\n",
              "      <th>-9_T</th>\n",
              "      <th>-8_A</th>\n",
              "      <th>-8_C</th>\n",
              "      <th>-8_G</th>\n",
              "      <th>-8_T</th>\n",
              "      <th>-7_A</th>\n",
              "      <th>-7_C</th>\n",
              "      <th>-7_G</th>\n",
              "      <th>-7_T</th>\n",
              "      <th>-6_A</th>\n",
              "      <th>-6_C</th>\n",
              "      <th>-6_G</th>\n",
              "      <th>-6_T</th>\n",
              "      <th>-5_A</th>\n",
              "      <th>-5_C</th>\n",
              "      <th>-5_G</th>\n",
              "      <th>-5_T</th>\n",
              "      <th>-4_A</th>\n",
              "      <th>-4_C</th>\n",
              "      <th>-4_G</th>\n",
              "      <th>-4_T</th>\n",
              "      <th>-3_A</th>\n",
              "      <th>-3_C</th>\n",
              "      <th>-3_G</th>\n",
              "      <th>-3_T</th>\n",
              "      <th>-2_A</th>\n",
              "      <th>-2_C</th>\n",
              "      <th>-2_G</th>\n",
              "      <th>-2_T</th>\n",
              "      <th>-1_A</th>\n",
              "      <th>-1_C</th>\n",
              "      <th>-1_G</th>\n",
              "      <th>-1_T</th>\n",
              "      <th>1_A</th>\n",
              "      <th>1_C</th>\n",
              "      <th>1_G</th>\n",
              "      <th>1_T</th>\n",
              "      <th>2_A</th>\n",
              "      <th>2_C</th>\n",
              "      <th>2_G</th>\n",
              "      <th>2_T</th>\n",
              "      <th>3_A</th>\n",
              "      <th>3_C</th>\n",
              "      <th>3_G</th>\n",
              "      <th>3_T</th>\n",
              "      <th>4_A</th>\n",
              "      <th>4_C</th>\n",
              "      <th>4_G</th>\n",
              "      <th>4_T</th>\n",
              "      <th>5_A</th>\n",
              "      <th>5_C</th>\n",
              "      <th>5_G</th>\n",
              "      <th>5_T</th>\n",
              "      <th>6_A</th>\n",
              "      <th>6_C</th>\n",
              "      <th>6_G</th>\n",
              "      <th>6_T</th>\n",
              "      <th>7_A</th>\n",
              "      <th>7_C</th>\n",
              "      <th>7_G</th>\n",
              "      <th>7_T</th>\n",
              "      <th>8_A</th>\n",
              "      <th>8_C</th>\n",
              "      <th>8_G</th>\n",
              "      <th>8_T</th>\n",
              "      <th>9_A</th>\n",
              "      <th>9_C</th>\n",
              "      <th>9_G</th>\n",
              "      <th>9_T</th>\n",
              "      <th>10_A</th>\n",
              "      <th>10_C</th>\n",
              "      <th>10_G</th>\n",
              "      <th>10_T</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   -10_A  -10_C  -10_G  -10_T  -9_A  -9_C  ...  9_G  9_T  10_A  10_C  10_G  10_T\n",
              "0      0      0      0      1     0     0  ...    0    0     0     0     0     1\n",
              "1      0      0      0      1     1     0  ...    1    0     1     0     0     0\n",
              "2      0      0      0      1     0     0  ...    0    1     0     0     1     0\n",
              "3      0      0      0      1     1     0  ...    0    1     0     0     0     1\n",
              "4      0      0      0      1     1     0  ...    1    0     1     0     0     0\n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfAOG8SBu24E",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the generalization performance of a logisitc regression model with hyperparameters $C=0.1$ on the data set `data_features_onehot_encoding` using 10-fold cross-validation. \n",
        "The `cross_val_score()` has a function parameter called `scoring` that allows you to set different scoring metrics.\n",
        "\n",
        "*Use the `cross_val_score()` function to compute the mean AUC of the CV-scores.* \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq2cZVNSu24F",
        "colab_type": "code",
        "outputId": "90e0e877-ac9a-462c-e83a-bda5a65e1a5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = LogisticRegression(C=0.1)\n",
        "\n",
        "###Start code here\n",
        "score_acc = np.mean(cross_val_score(model,data_features_onehot_encoding,data.label,cv=10,scoring=\"roc_auc\"))\n",
        "###End code here\n",
        "\n",
        "print(score_auc)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9867797540208135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqh-I3zuu24L",
        "colab_type": "text"
      },
      "source": [
        "*What is the AUC on `data_test`?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeCkxuubu24M",
        "colab_type": "code",
        "outputId": "db826eeb-2be6-465a-afdd-5ef6dd84aeed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "###Start code here\n",
        "data_test_features_onehot_encoding = pd.DataFrame(data_test[\"sequence\"].apply(remove_AG).apply(DNA_onehot_encoding).tolist())\n",
        "model.fit(data_features_onehot_encoding,data.label)\n",
        "predictions = model.predict_proba(data_test_features_onehot_encoding)\n",
        "score_auc = metrics.auc(data_test.label,predictions[:,1])\n",
        "###Start code here\n",
        "\n",
        "print(score_acc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC=0.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w-jdU-gu24Q",
        "colab_type": "text"
      },
      "source": [
        "Is this close to what your CV is telling you?\n",
        "\n",
        "We have used hyperparameter $C=0.1$ for the logistic regression model. \n",
        "\n",
        "*Is there a better value for this regularization parameter (use `GridSearchCV`)?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B63LA0zwu24S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "search_space = [0.001,0.01,0.1,1,10,100]\n",
        "\n",
        "###Start code here\n",
        "params = dict(C=search_space)\n",
        "grid_search = GridSearchCV(model, param_grid=params)\n",
        "grid_search.fit(data_features_onehot_encoding,data.label)\n",
        "###End code here\n",
        "\n",
        "print(grid_search.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjoFP1_bu24W",
        "colab_type": "text"
      },
      "source": [
        "*What is the 10-CV AUC performance with this value for $C$?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWxVj0hRu24X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Start code here\n",
        "model = LogisticRegression(C=1)\n",
        "score_auc = np.mean(cross_val_score(model,data_features_onehot_encoding,data.label,cv=10,scoring=\"roc_auc\"))\n",
        "###Start code here\n",
        "\n",
        "print(score_auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytpwmh2wu24c",
        "colab_type": "text"
      },
      "source": [
        "*What is the AUC performance on the test set for this value of $C$?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5906bHvu24d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Start code here\n",
        "model.fit(data_features_onehot_encoding,data.label)\n",
        "predictions = model.predict_proba(data_test_features_onehot_encoding)\n",
        "score_auc = metrics.auc(data_test.label,predictions[:,1])\n",
        "###End code here\n",
        "\n",
        "print(score_auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "wRe1CLnUu24l",
        "colab_type": "text"
      },
      "source": [
        "Is this closer to the AUC you computed using 10-CV?\n",
        "\n",
        "Let's see how the model is making predictions (what patterns it extracted). In scikit-learn a fitted model has its modelparameters stored in `.coef_[0]`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f-NBEUt4AjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.coef_[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdPAICuc4NWT",
        "colab_type": "text"
      },
      "source": [
        "For logistic regression this is one modelparameter for each feature (plus the interecept, which is not in `.coef_[0]`). \n",
        "\n",
        "Recall that for logistic regression a prediction is made by multiplying each fitted modelparameter with the corresponding feature, summing them and then squeezing this sum between 0 and 1 through the logistic function. Since all feature have values 0 or 1 the modelparameter values indicate the importance of a feature during prediction.\n",
        "\n",
        "For plotting we will put the feature names and modelparameter values in a new DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mnte18-u242",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "F_importances = []\n",
        "for feature_name, modelparameter in zip(data_features_onehot_encoding.columns,model.coef_[0]):\n",
        "    F_importances.append([feature_name,modelparameter])\n",
        "F_importances = pd.DataFrame(F_importances,columns=[\"feature_name\",\"importance\"])\n",
        "F_importances.head()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SwWB_xQ8w8g",
        "colab_type": "text"
      },
      "source": [
        "*Use the Seaborn `.barplot()` method to plot this DataFrame:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_thWFCY894M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(18,8))\n",
        "chart = sns.barplot(x=\"feature_name\",y=\"importance\",data=F_importances)\n",
        "chart.set_xticklabels(chart.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0N9sbu79xoi",
        "colab_type": "text"
      },
      "source": [
        "*Can you make a better plot?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntsnD5Kwu25B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_nuc(x):\n",
        "    return(x.split(\"_\")[1])\n",
        "\n",
        "def get_position(x):\n",
        "    if x.split(\"_\")[0] == \"A\": return 0\n",
        "    if x.split(\"_\")[0] == \"G\": return 0\n",
        "    return(int(x.split(\"_\")[0]))\n",
        "\n",
        "F_importances[\"nuc\"] = F_importances[\"feature_name\"].apply(get_nuc)\n",
        "F_importances[\"position\"] = F_importances[\"feature_name\"].apply(get_position)\n",
        "\n",
        "F_importances.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5haGvAHu25c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18,8))\n",
        "sns.barplot(x=\"position\",y=\"importance\",hue=\"nuc\",data=F_importances)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1uafole2Y-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}