{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Philosopher:400,700,400italic,700italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>\n",
       "\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "\n",
       "#notebook_panel { /* main background */\n",
       "    background: #888;\n",
       "    color: #f6f6f6;\n",
       "}\n",
       "\n",
       "div.cell { /* set cell width to about 80 chars */\n",
       "}\n",
       "\n",
       "div #notebook { /* centre the content */\n",
       "    background: #fff; /* white background for content */\n",
       "    margin: auto;\n",
       "}\n",
       "\n",
       "#notebook li { /* More space between bullet points */\n",
       "margin-top:0.8em;\n",
       "}\n",
       "\n",
       "/* draw border around running cells */\n",
       "div.cell.border-box-sizing.code_cell.running {\n",
       "    border: 3px solid #111;\n",
       "}\n",
       "\n",
       "/* Put a solid color box around each cell and its output, visually linking them together */\n",
       "div.cell.code_cell {\n",
       "    /*background-color: rgba(171,165,131,0.3); /*\n",
       "    border-radius: 10px; /* rounded borders */\n",
       "    padding: 1em;\n",
       "    /*margin-top: 1em;*/\n",
       "}\n",
       "\n",
       "div.text_cell_render{\n",
       "    font-family: 'Open Sans', Helvetica;\n",
       "    line-height: 140%;\n",
       "    font-size: 105%;\n",
       "    /*margin-top:15px;*/\n",
       "    margin-bottom:8px;\n",
       "    text-align:justify;\n",
       "}\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Open Sans',sans-serif;\n",
       "    font-weight: 100;\n",
       "    font-size: 30pt;\n",
       "    line-height: 100%;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    font-weight: 700;\n",
       "    font-size: 24pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(171,165,131);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}    \n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    margin-top:12px;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: italic;\n",
       "    color: rgb(95,92,72);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {\n",
       "    font-family: 'Alegreya Sans', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 16pt;\n",
       "    color: grey;\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 {\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 10pt;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".CodeMirror{\n",
       "        font-family: \"PT Mono\";\n",
       "        font-size: 100%;\n",
       "}\n",
       "\n",
       ".output_area {\n",
       "\tmargin-top:20px;\n",
       "}\n",
       "\n",
       ".output_stderr {\n",
       "\tdisplay:none;\n",
       "\t}\n",
       "\n",
       ".output_subarea {\n",
       "\tdisplay: block;\n",
       "    margin: 0 auto;\n",
       "}\n",
       "\n",
       ".output_png img {\n",
       "    display: block;\n",
       "    margin-left: auto;\n",
       "    margin-right: auto;\n",
       "}\n",
       "\n",
       ".prompt {\n",
       "\tvisible: false;\n",
       "\t}\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "compomics_import = imp.load_source('compomics_import', 'compomics_import.py')\n",
    "from IPython.core.display import HTML\n",
    "css_file = 'my.css'\n",
    "HTML(open(css_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will build a classification model for gene splice site prediction. It is a problem arising in computational gene finding and concerns the recognition of splice sites that mark the boundaries between exons and introns in eukaryotes. Introns are spliced from premature mRNAs after transcription. The vast majority of splice sites are characterized by the presence of specific dimers on the intronic side of the splice site: GT for donor and AG for acceptor sites. Yet, only about 0.1-1% of all GT and AG occurrences in the genome represent true splice sites. \n",
    "\n",
    "Load the acceptor site training data set *acceptor_sites_dataset_train.csv* in a Pandas DataFrame called `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first 5 rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only two columns. The column \"sequence\" contains a DNA sequence with length 22. The nucleotides at positions 11 and 12 in the sequence are always \"A\" and \"G\" respectively, so these positions are candidate gene acceptor sites. The column \"target\" indicates the class: 1 for \"is acceptor site\" and -1 for \"is not acceptor site\". The goal is to predict the target from the local context sequence of the candidate acceptor site. Let's see how many data points belong to each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-030a1116a83a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Machine Learning algorithms we well apply DNA sequences cannot be used as input. We will need to compute features from the DNA sequences that will allow us to detect true acceptor sites, a process known as **feature engineering**. \n",
    "\n",
    "In the first practicum we have seen the Pandas `apply()` function that allows us the process the values in a DataFrame column to create a new column. We will apply this function to compute feature vectors from the `sequence` column in the `data` DataFrame.  \n",
    "\n",
    "We don't need to compute features from the middle AG dinculeotide in the local context sequence. Why?\n",
    "\n",
    "Let's remove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_AG(x):\n",
    "    return x[0:10]+x[12:22]\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "data[\"sequence\"] = data[\"sequence\"].apply(remove_AG)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the following function do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNA_int_encoding(x):\n",
    "    encoding = []\n",
    "    for nuc in x:\n",
    "        if nuc == 'A':\n",
    "            encoding.append(0)\n",
    "        elif nuc == 'C':\n",
    "            encoding.append(1)\n",
    "        elif nuc == 'G':\n",
    "            encoding.append(2)\n",
    "        elif nuc == 'T':\n",
    "            encoding.append(3)\n",
    "        else:\n",
    "            print(\"Found non-nucleotide in %s\"%x)\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function on the `sequence` column in the `data` DataFrame to create a Pandas `Series` called `data_features_int_encoding` with feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we put these feature vectors back in a Pandas DataFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features_int_encoding = pd.DataFrame(data_features_int_encoding.tolist())\n",
    "\n",
    "data_features_int_encoding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does `data_features_int_encoding` contain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the generalization performance of a Logisitc Regression model with hyperparameters $C=0.1$ on the data set `data_features_int_encoding` using 10-fold cross-validation. Use the `cross_val_score()` function to compute the mean accuracy of the CV-scores (use `np.mean()` to compute the mean value). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this number mean?\n",
    "\n",
    "Load the acceptor site test data set *acceptor_sites_dataset_test.csv* in a Pandas DataFrame called `data_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the same feature vectors for the test set (create a DataFrame `data_test_features_int_encoding` that contains the feature vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit a Logistic Regression model ($C=0.1$) on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `predict()` function of the `LinearRegression()` object to predict class labels for the instances in the test set (put the prediction in a variable called `predictions`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn offers many metrics to evaluate model predictions. These functions are contained in the `metrics` module of `sklearn`. Can you find how to compute the accuracy of these predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy above 90% seems like a good score. But is it? Let's consider a model that predicts class \"-1\" for all test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_zero = [-1]*len(data_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the accuracy of these predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this should be a good score as well, even though we did not learn anything.\n",
    "\n",
    "For classification tasks where the classes are highly imbalanced accuracy is not a good metric to evaluate the generalization performance. In fact, if there are 0.1% AG dinucleotides in a genome that are true acceptor sites then a model that predicts class \"-1\" for each AG would have an accuracy of 99.9%.\n",
    "\n",
    "We have seen how a ROC curve plots the true positives rate against the false positives rate. Both these metrics focus on the positive class, in our case the true acceptor sites. These metrics are much more suitable to evalute the performance of models on tasks with highly imbalanced classes. To transform a ROC curve into one metric we can use the area under the curve (AUC). \n",
    "\n",
    "What is the AUC score of the predictions computed by the linear regression model we fitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a negative value. This is because to compute the ROC we need the predictions to be scores (a continuous value) rather than class labels (discrete values). \n",
    "\n",
    "For logistic regression these scores are the class probabilities predicted by the model. We can obtain them using the `predict_proba()` function of the `LogisticRegression()` object as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does variable `predictions` contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and second column contains the predicted probabilities for class '-1' and '1' respectively. To compute the AUC we need to use the positive class probabilities. What is the AUC now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this good generalization performance?\n",
    "\n",
    "Transforming categorical features into ordered integers is maybe not a good idea as the nucleotides don't have any ordering. It is better to transform a categorical feature into one binary feature for each category (known as *one-hot* encoding). \n",
    "\n",
    "We can do this with the following function that again computes feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNA_onehot_encoding(x):\n",
    "    encoding = []\n",
    "    for nuc in x:\n",
    "        if nuc == 'A':\n",
    "            encoding.extend([1,0,0,0])\n",
    "        elif nuc == 'C':\n",
    "            encoding.extend([0,1,0,0])\n",
    "        elif nuc == 'G':\n",
    "            encoding.extend([0,0,1,0])\n",
    "        elif nuc == 'T':\n",
    "            encoding.extend([0,0,0,1])\n",
    "        else:\n",
    "            encoding.extend([0,0,0,0])\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas DataFrame called `data_features_onehot_encoding` that contains the *one-hot* encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the generalization performance of a logisitc regression model with hyperparameters $C=0.1$ on the data set `data_features_onehot_encoding` using 10-fold cross-validation. Use the `cross_val_score()` function to compute the mean AUC of the CV-scores. The `cross_val_score()` has a function parameter called `scoring` that you need to replace the *accuracy* metric with the *AUC* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the AUC on `data_test`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this close to what your CV is telling you?\n",
    "\n",
    "We have used hyperparameter $C=0.1$ for the logistic regression model. Is there a better value for this regularization parameter (use `GridSearchCV`)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "search_space = [0.001,0.01,0.1,1,10,100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the 10-CV AUC performance with this value for $C$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the AUC performance on the test set for this value of $C$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Is this closer to the AUC you computed using 10-CV?\n",
    "\n",
    "Given this analysis, is the test set still *unseen data*?\n",
    "\n",
    "The Logistic Regression algorithm fits a model parameter for each feature. We can use the value of these model parameters to investigate the relevance or importance of a feature in the model. \n",
    "\n",
    "First we give each feature a recognizable name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "\n",
    "for i in range(-10,0,1):\n",
    "    for nuc in ['A','C','G','T']:\n",
    "        columns.append(\"%i_%s\"%(i,nuc))\n",
    "for i in range(1,11,1):\n",
    "    for nuc in ['A','C','G','T']:\n",
    "        columns.append(\"%i_%s\"%(i,nuc))\n",
    "        \n",
    "data_features_onehot_encoding.columns = columns\n",
    "data_features_onehot_encoding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit a Logistic Regression model ($C=1$) on the data set `data_features_onehot_encoding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted model parameters can be found in the `.coef_[0]` parameter of the model. Print the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the most important feature in your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the feature importances as a clear and informative graph. Can you understand the code (make it work for your model)? What does the plot show?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "F_importances = []\n",
    "for feature_name,lr_coefficient in zip(data_features_onehot_encoding.columns,model.coef_[0]):\n",
    "    F_importances.append([feature_name,lr_coefficient])\n",
    "    \n",
    "F_importances = pd.DataFrame(F_importances,columns=[\"feature_name\",\"importance\"])\n",
    "print(F_importances.head())    \n",
    "\n",
    "def get_nuc(x):\n",
    "    return(x.split(\"_\")[1])\n",
    "\n",
    "def get_position(x):\n",
    "    if x.split(\"_\")[0] == \"A\": return 0\n",
    "    if x.split(\"_\")[0] == \"G\": return 0\n",
    "    return(int(x.split(\"_\")[0]))\n",
    "\n",
    "F_importances[\"nuc\"] = F_importances[\"feature_name\"].apply(get_nuc)\n",
    "F_importances[\"position\"] = F_importances[\"feature_name\"].apply(get_position)\n",
    "\n",
    "print(F_importances.head())\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.factorplot(x=\"position\", y=\"importance\", hue=\"nuc\", data=F_importances, aspect=2)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
