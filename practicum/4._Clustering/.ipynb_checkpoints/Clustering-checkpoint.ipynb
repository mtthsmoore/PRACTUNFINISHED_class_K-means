{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "compomics_import = imp.load_source('compomics_import', '../../compomics_import.py')\n",
    "from IPython.core.display import HTML\n",
    "css_file = '../../my.css'\n",
    "HTML(open(css_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2013 a data set was published [1] about human activity recognition using smartphones. For a group of 30 volunteers within an age bracket of 19-48 years each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, 3-axial linear acceleration and 3-axial angular velocity were captured at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). From each window, a vector of features was obtained by calculating variables from the time and frequency domain. You can watch this small video to learn more about how the data was collected:\n",
    "\n",
    "\n",
    "[![video](http://img.youtube.com/vi/XOEN9W05_4A/0.jpg)](http://www.youtube.com/watch?v=XOEN9W05_4A \"Collecting Data\")\n",
    "\n",
    "\n",
    "> [1] D. Anguita, A. Ghio, L. Oneto, X. Parra and J. L. Reyes-Ortiz. *A Public Domain Dataset for Human Activity Recognition Using Smartphones*. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.\n",
    "\n",
    "Lets load the data set, the file is called \"samsungData.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains the features and two additional columns: 'subject' and 'activity'. The 'subject' is the anonymous identifier of the person from which the measurements were recorded. The 'activity' column contains one of the six activities that were annotated. How many rows are there for each person? How many for each activity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Person '25' has the most rows in the data set. Create a variable `data_25` that contains only the rows for person '25'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remove column 'subject' from `data_25`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also remove the column 'activity' from `data_25` and store in a variable called `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `data_25` only contains the features. Investigate the distribution and ranges of the first 100 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some data sets are very hard to normalize. We see features with very different ranges and very different shapes of distributions. Start by standardizing all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again investigate the first 100 features, but this time set the argument `flierprops` of the pandas dataframe `boxplot()` function to '`dict(marker='o', markersize=5)`'. This will show the distribution outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduct the impact of these outlying values we can trim them to a certain range. This means that if a feature value is less or more than the trimming values it is replace by the closest trimming value. The pandas dataframe has a function called [`clip()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.clip.html) that will trim the features within a minimum and a maximum value. Trim the data set within [-3,3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the feature distributions look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is ready for K-means clustering. What would be a good value for the number of clusters $k$ that the K-means++ implementation of scikit-learn requires as hyperparameter? Use the 'silhouette coefficient' and 'inertia' metrics to evaluate different values for $k$. Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would you conclude from these plots? Create scikit-learn K-means++ object called `kmeans` and fit a model with 6 clusters (this was the number of activities in the data set). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas contains a function `crosstab()` that evaluates how well the clusters match the true grouping by activity. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(kmeans.labels_,target)\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this cross-table tell you about how well the data points are clustered for each activity?\n",
    "\n",
    "Now will perform hierarchical clustering on this normalized data set. First we create a python list `a_colors` that contains the target activities as colors. This list can be used for the `row_colors` argument of the seaborn `clustermap()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities2color = {}\n",
    "activities2color['laying'] = 'purple'\n",
    "activities2color['sitting'] = 'green'\n",
    "activities2color['standing'] = 'blue'\n",
    "activities2color['walk'] = 'yellow'\n",
    "activities2color['walkdown'] = 'brown'\n",
    "activities2color['walkup'] = 'red'\n",
    "\n",
    "a_colors = [activities2color[x] for x in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `clustermap()` to create a row and column dendogram of the data as a heatmap using single-linkage. In the plot the rows need to be the data points. Use the `row_colors` argument to add the true activities to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
